---
title: "Instacart Market Basket Analysis"
author: "Sam Playle"
date: "28 June 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = F, warning = F, message = F}
library(dplyr); library(ggplot2)
```

## Introduction

This analysis is based on Instacart's dataset of 3 million anonymized orders, which is discussed in a blog post here: https://tech.instacart.com/3-million-instacart-orders-open-sourced-d40d29ead6f2

The goal of the Kaggle competition is to predict which items, from among those previously purchased, will be included in a customer's next order. 
https://www.kaggle.com/c/instacart-market-basket-analysis

## Exploratory analysis

### Data

The data comprise five .csv files.
```{r echo = T}
data <- list.files("../Data")
data
```


Let's have a look at them. The first (alphabetically) is `aisles.csv`.
```{r echo = T}
aisles <- read.csv("../Data/aisles.csv")
dim(aisles)
head(aisles)
```

We see there are 134 "aisles", each of which corresponds to a different collection of groceries. 

The next .csv file is `departments.csv`.
```{r echo = T}
depts <- read.csv("../Data/departments.csv")
dim(depts)
head(depts)
```

So there are 21 departments.

Next we have the biggest .csv files. `order_products__prior.csv` contains previous order contents for all customers. 

```{r echo = T}
opp <- read.csv(file = "../Data/order_products__prior.csv")
dim(opp)
head(opp)
```

So there are 32,434,489 data points in the prior order dataset. For each data point, we get the `order_ID` telling us which particular order the data point corresponds to; `product_ID` telling us which type of product that data point is, `add_to_cart_order` telling us at which point in carrying out the order was the item chosen, and `reordered` which tells us whether or not the customer had previously ordered the item.

Next let's have a look at the `order_products__train.csv' file.

```{r echo = T}
opt <- read.csv(file = "../Data/order_products__train.csv")
dim(opt)
head(opt)
```

We see it contains 1,384,617 observations. The columns are the same as in the `order_products__prior.csv` file.

The `orders.csv' file tells us information about the orders, including which dataset (prior, training or test) it belongs to. 

```{r echo = T}
orders <- read.csv(file = "../Data/orders.csv")
dim(orders)
head(orders)
```

We see there are 3,421,083 orders in the dataset. Each one has a `user_id`, an `order_number`, a weekday `order_dow` and time `order_hour_of_day` for the order, and `days_since_prior_order`, i.e. how long it has been since the user's previous order.

The number of unique users is about 200 thousand:
```{r echo = T}
length(
  unique(
    orders$user_id
    )
  )
```

Finally let's have a look at the `products.csv` file:  

```{r echo = T}
products <- read.csv(file = "../Data/products.csv")
dim(products)
head(products)
```

There are 49,688 different products; for each one as well as a `product_id` we get a `product_name`, an `aisle_id` and a `department_id`.

### Output

Let's have a look at the sample submission to see what format our output should be in: 

```{r echo = T}
sampsub <- read.csv(file = "../Data/sample_submission.csv", stringsAsFactors = F)
dim(sampsub)
head(sampsub)
```

We see that there are 75,000 rows with two columns. The first column is the order ID; so the idea is that given the order ID we should predict which products are included (from among those that the customer has previously ordered). The ordered products should be given as a space-separated list. It's possible that no repeat products were ordered; in this case the submitted answer for "products"" should be "None". https://www.kaggle.com/c/instacart-market-basket-analysis#evaluation

In the sample submission, every basket is identical.
```{r echo = T}
all(sampsub$products==sampsub$products[1])
```

Let's see what products are in the sample basket by subsetting the `products` dataframe to just the rows with these two product IDs: 
```{r echo = T}
sampbasket <- as.numeric(strsplit(sampsub$products[1],"\\ ")[[1]])

products[
  products[,"product_id"] %in% sampbasket
  ,]
```

This explains why they chose the name "Going Bananas Benchmark"!

The scores will be computed from the mean F1 score. This is defined as
$$
F_1 = 2 \cdot \frac{p \cdot r }{p + r} \, , 
$$

where $p$ is the *precision*, i.e. the number of correct product IDs divided by the number of product IDs submitted, and $r$ is the *recall*, i.e. the number of correct product IDs divided by the number of product IDs that there should have been.

### Partitioning off a validation set

Let's split a dataset off of the training set to give us an estimated out-of-sample error rate of our analysis. We should not use the validation set for any training or preliminary investigation. 

Let's get the IDs of the orders that are in the training set, and sample 20% of them as a validation set.

```{r echo = T}
trainorders <- orders[(orders$eval_set=="train"),"order_id"]
set.seed(9383)
intrain <- as.logical(
  rbinom(
    n = length(trainorders), 
    size = 1, 
    prob = 0.8
    )
  )
trainingIDs <- trainorders[intrain]
validationIDs <- trainorders[!intrain]
length(trainingIDs)
length(validationIDs)
```

Now we can set up a function to evaluate how accurate our attempts are. Let's assign the "going bananas benchmark" to our validation set. 

```{r echo = T}
valsample <- data.frame(order_id = validationIDs, products = sampsub[1,2])
valsample[,2] <- as.character(valsample[,2])
head(valsample)
```

To evaluate this, we need to find the "ground truth" for our validation set. For each order number, we need to get a list of products which appear in that order *and* which are repeat orders. Let's write a function to do this:

```{r echo = T}
getrepeatbasket <- function(order_id){
  orderprods <- opt[opt[,"order_id"]==order_id 
                    & opt[,"reordered"],]
  orderprods
}

listprods <- function(basket){
  prodvec <- basket$product_id
  spaced <- paste(prodvec, collapse = ' ')
  spaced
}

orderprods <- function(order_id){
  listprods(getrepeatbasket(order_id))
}
```

This function takes as its arguments an order number and a prediction for which items will be contained in that order, and outputs the $F_1$ score of that prediction:

```{r echo = R}
f1order <- function(order_id, productguess){
  pgsplit <- strsplit(productguess, split = " ")[[1]]
  ptrue <- getrepeatbasket(order_id)$product_id
  correct <- pgsplit %in% ptrue
  p <- mean(correct)
  r <- sum(correct) / length(ptrue)
  ifelse(
    p != 0 & r != 0,
    2*p*r/(p+r),
    0
  )
}
```

This function takes a data frame of order numbers and predicted products and outputs the mean $F_1$ score for the data frame.

```{r echo = T}
getf1 <- function(guessdf){
  x <- NULL
  for(i in 1:nrow(guessdf)){
    # Uncomment for updates
    # if(i %% 100 == 0) print(c(i, mean(x)))
    f1 <- f1order(guessdf[[i,1]],guessdf[[i,2]])
    x <- c(x, f1)
  }
  mean(x)
}
```

Let's use the `getf1()` function on the validation set with the banana benchmark. The computation takes quite a long time so we will save the output after running it once. 

```{r echo = T}
if(!file.exists("validationbenchmark.rds")){
  validationbenchmark <- getf1(valsample)
  saveRDS(x, file = "validationbenchmark.rds")
} else {
  validationbenchmark <- readRDS("validationbenchmark.rds")
}
validationbenchmark
```

So the benchmark guess for the validation dataset is about 0.000521. On the other hand, the benchmark guess for the *test* dataset, available on the leaderboard at https://www.kaggle.com/c/instacart-market-basket-analysis/leaderboard , is 0.000545. These two scores are within 5% of each other, which is reassuring because it tells us that we are computing the $F_1$ score correctly, and that there is some consistent structure in the dataset for us to find as expected (i.e. the orders are not just random).

## Exploratory graphs

### Number of orders

Let's have a look at how many orders there are per user, given by `table(orders$user_id)`. Let's plot a histogram:
```{r echo = T}
qplot(n, data = count(orders, user_id), bins = 97)
```

We can see that the number of orders in the dataset is between 4 and 100, as described. The count is strictly decreasing as a function of the number of orders, except at 100. This suggests that all customers with $\geq 100$ orders have been added into the 100 box.

### Popular days to order

We can plot this with
```{r echo = T}
qplot(as.factor(orders$order_dow))
```
This seems to show that days 0 and 1 are the most popular - suggesting that these two days might be weekend days.

### Popular times of day to order

We can see which times of day are popular to order with the following plot:
```{r echo = T}
qplot(as.factor(orders$order_hour_of_day), xlab = "Time of day")
``` 
This shows that the purchases peak once at 10a.m. and again at 3p.m.

We've seen that whether or not it's a weekend (presuming this is what days "0" and "1" are) has a significant impact on the number of orders made. Does it also impact what time of days the orders are made? Apparently not:
```{r echo = T}
day.type <- with(orders, as.factor(order_dow == 0 | order_dow == 1))
levels(day.type) <- c("Weekday", "Weekend")
ggplot(orders, aes(order_hour_of_day, fill = day.type)) + labs(x = "Time of day") + geom_density(alpha = 0.2, adjust = 3)
```

### Number of days between orders

```{r echo = T}
qplot(days_since_prior_order, data = orders, xlab = "Days since prior order", bins = 30, na.rm = T)
```

This is obviously cut off at a maximum of 30 days, with any higher value counting as 30. The histogram seems to peak at 7 days, with further local maxima at other multiples of 7 days, suggesting that people tend to do their shopping at weekly intervals. 

### Size of orders

```{r echo = T}
count(opp, order_id) %>% select(n) %>% summary()
qplot(count(opp, order_id)$n, geom = "histogram", xlim = c(0,50), bins = 51, na.rm = T)
```

### How consistent are users with their order sizes?

```{r echo = T}
count(opp, order_id) %>% inner_join(orders) %>% select(user_id, n) %>% group_by(user_id) %>% summarize(sd = sd(n)) %>% select(sd) %>% summary()
```
So 50% of users have a standard deviation of their order size between 2.3 and 5.6, with the mean user standard deviation between 4.3. 

## A better benchmark

A better benchmark (than just giving bananas to everyone) would be to predict that a user buys a product if it appears in more than 50% of their other orders.

First let's define a function which takes a `user_id` and outputs the desired output. 

We want to use both the prior and training dataframes to compute the means.

First let's look at a single example so we can work out how to do this. Let's look at user `178520`. 

```{r echo = T}
ord1 <- orders %>% filter(user_id == 178520) %>% select(order_id) %>% inner_join(opp) 
n1 <- ord1 %>% distinct(order_id) %>% nrow()
fracs1 <- ord1 %>% count(product_id) %>% mutate(frac = n/n1)
```

We see that very few of the products are chosen in over 50% of orders, so this seems to be quite conservative:
```{r echo = T}
qplot(fracs1$frac)
```

Actually there are six items orders over half the time:
```{r echo = T}
guess1 <- fracs1 %>% filter(frac >= 0.5)
guess1 %>% inner_join(products) %>% select(frac, product_name)
```

So this person mostly buys breakfast supplies and energy drinks. 

Let's put this as our guess for this one user:
```{r echo = T}
ans1 <- guess1$product_id %>% paste(collapse = " ")
val1 <- orders %>% filter(eval_set == "train", user_id == 178520) %>% select(order_id) %>% mutate(products = ans1)
val1
```
We can find the F1 score of this one example by running 
```{r echo = T}
f1order(2331095, ans1)
```
Which is not that bad; the Kaggle leaderboard is led (at the time of writing) by a score of 0.403.

Now we need to apply the same manipulations automatically to the whole prior dataset. 

```{r echo = T}
practice <- data.frame(user_id = c(1,1,1,1,2,2,2,2,2), order_id = c(1,1,2,2,3,3,3,4,4), product_id = c(7,9,7,10,8,11,7,6,11))

ordercount <- practice %>% group_by(user_id) %>% summarize(norders = n())

practice %>% group_by(user_id, product_id) %>% summarize(count = n()) %>% inner_join(ordercount) %>% mutate(frac = count/norders) %>% filter(frac >= 0.5)
```

```{r echo = T}

## Making a data frame listing the fraction of times a product appeared
## in a user's order

## The computation takes a bit of time so let's save the output

if(!file.exists("orderfracs.rds")){
##  
## Link the prior orders to the order data to get user IDs
##
benchdat <- opp %>% inner_join(orders) %>% 
  ##
  ## Keep only the user_id, order_id and product_id columns
  ##
  select(user_id, order_id, product_id)
##
## Make a new data frame norders listing the number
## of distinct orders for each user
##
norders <- benchdat %>% group_by(user_id) %>% summarize(number_orders = n_distinct(order_id))
##
## Make a new data frame listing which fraction of a user's
## orders include a product.
## First count the occurrences of each product
##
orderfracs <- benchdat %>% group_by(user_id, product_id) %>% summarize(count = n()) %>% 
  ##
  ## Then join to the data frame with the number of orders
  ## per user and compute the fraction
  ##
  inner_join(norders) %>% mutate(frac = count/number_orders) %>% 
  ##
  ## Return only the fields we need
  ##
  select(user_id, product_id, frac) 

saveRDS(orderfracs, file = "orderfracs.rds")
} else {
orderfracs <- readRDS("orderfracs.rds")
}
```

```{r echo = T}
bench2 <- orderfracs %>% filter(frac >= 0.5)
```

Putting the data in the right form:

```{r echo = T}
filtered.to.form <- function(df){
  df %>% group_by(user_id) %>% mutate(products = paste0(product_id, collapse = " ")) %>% select(user_id, products) %>% unique()
}
```

```{r echo = T}
bench2form <- filtered.to.form(bench2)
```

Now we need to use this to get predictions

```{r echo = T}
form.to.train <- function(df){
  filter(orders, eval_set == "train") %>% left_join(df) %>% select(order_id, products) %>% mutate(products = ifelse(is.na(products),"",products))
}
```

```{r echo = T}
guesses1 <- form.to.train(bench2form)
```

Now we need to compare this to the `ground truth'. 

First let's make a data frame containing the ground truth:
```{r echo = T}
groundtruth <- filter(orders, eval_set == "train") %>%  left_join(opt) %>% filter(reordered == 1) %>% select(order_id, product_id) %>% group_by(order_id) %>% mutate(truth = paste0(product_id, collapse = " ")) %>% select(order_id, truth) %>% unique()
```

Create some functions to compute the F1 score:
```{r echo = T}
string.ratio <- function(s1, s2){
    mean( strsplit(s1, split = " ")[[1]] %in% strsplit(s2, split = " ")[[1]] )
}

f1strings <- function(s1, s2){
  p = string.ratio(s1, s2)
  r = string.ratio(s2, s1)
  f1 = ifelse(p != 0 & r != 0,
              2 * p * r / (p + r),
              0)
  f1
}
```

```{r echo = T}
train.to.f1 <- function(df){
  groundtruth %>% inner_join(df) %>% mutate(f1 = f1strings(products, truth)) %>% select(order_id, f1) 
}
```

```{r echo = T}
f1scores <- train.to.f1(guesses1)
mean(f1scores$f1)
```

So the score is about 27.9%, which is OK.

Let's generate a prediction for the test dataset to submit to Kaggle. 
```{r echo = T}
# Let's make the data frame with the same pipeline as above

guess1test <- filter(orders, eval_set == "test") %>% left_join(bench2form) %>% select(order_id, products) %>% mutate(products = ifelse(is.na(products),"None",products))

write.csv(guess1test, file = "guess1.csv", quote = F, row.names = F)
```
which, when uploaded to Kaggle, gets a score of about 28.7%.

## Finding the best cutoff

Maybe it would be better to guess all items bought more than $q$ of the time were in a given basket, where $q$ is a fraction between 0 and 1. Let's compute and work out which fraction gives the highest score.

```{r echo = T}
if(!file.exists("scores.rds")){
  scores <- NULL
  for (i in 0:50){
    print(i)
    p <- 0.1 + i*0.01
    pguess <- filter(orderfracs, frac >= p)
    f1sc <- pguess %>% filtered.to.form() %>% form.to.train() %>% train.to.f1()
    score <- mean(f1sc$f1)
    scores <- c(scores, score)
  }
  } else {
  scores <- readRDS("scores.rds")
  }
  pmax <- 0.1 + 0.01 * (0:50)[which(scores == max(scores))]
  plot(0.1 + 0.01 * (0:50), scores, xlab = "Cutoff fraction")
  abline(v = pmax)
```

## Uploading the test set with this cutoff

```{r echo = T}
# Let's make the data frame with the same pipeline as above

prods.26 <- orderfracs %>% filter(frac >= 0.26) %>% filtered.to.form()

test.26 <- filter(orders, eval_set == "test") %>% left_join(prods.26) %>% select(order_id, products) %>% mutate(products = ifelse(is.na(products),"None",products))

write.csv(test.26, file = "cutoff26.csv", quote = F, row.names = F)
```

This gives a score on Kaggle of 0.3326.

## A model taking into account time since previous order

Let's make a model using **logistic regression** taking account of two predictors: the length of time since the previous order *and* the fraction of previous orders on which the item was bought.

We need to get the data into a particular form to do this; we need to make a data frame with the following columns:

 * `order_id`
 * previous items ordered by the user
 * fraction of previous orders the user bought this item
 * how many days was it since the previous order?
 * did the user buy it this time yes/no?
 
Let's start by making a data frame which, for every order in the training set, lists all previous orders by the user and their probability.

```{r echo = T}
word.in.sentence <- function(word, sentence){
    word %in% strsplit(sentence, split = " ")[[1]]
}
```

```{r echo = T}
if(!file.exists("prodsinorderdays.RDS")){
trainordersdays <- orders %>% filter(eval_set == "train") %>% select(order_id, user_id, days_since_prior_order)

trainordersprods <- opt %>% filter(reordered == 1) %>% group_by(order_id) %>% mutate(prods = paste0(product_id, collapse = " "))  %>% select(order_id, prods) %>% unique()

prodsinorderdays <- trainordersdays %>% inner_join(orderfracs) %>% inner_join(trainordersprods) %>% group_by(order_id) %>% mutate(inorder = word.in.sentence(product_id, prods)) %>% data.frame()

saveRDS(prodsinorderdays, "prodsinorderdays.RDS")
} else {
  prodsinorderdays <- readRDS("prodsinorderdays.rds")
}

head(prodsinorderdays)
```

Now we have the data frame in the form we need, let's train a logistic regression model with `days_since_prior_order` and `frac` as the covariates to predict `inorder`:
```{r echo = T}
if(!file.exists("dayfracfit.rds")){
dayfracfit <- glm(inorder ~ frac + days_since_prior_order, data = prodsinorderdays, family = binomial)
saveRDS(dayfracfit, "dayfracfit.rds")
} else {
  dayfracfit <- readRDS("dayfracfit.rds")
}

summary(dayfracfit)
```

Now, with this model trained, let us make predictions on the test dataset. We need to get a data frame which has the test order numbers with `frac` and `days_since_prior_order` as its columns. 
```{r echo = T}
testfracdaysdf <- orders %>% filter(eval_set == "test") %>% select(order_id, user_id, days_since_prior_order) %>% inner_join(orderfracs)

predtestfracdays <- predict(dayfracfit, newdata = testfracdaysdf, type = "response")
```

Now, this model outputs an updated "probability" of a certain item being in an order which is an increasing function of the fraction of prior orders and a *decreasing* function of the time since the previous order was made --- the longer a user waits between orders, the *less* likely it is that they will buy something! Is this too simple? 

```{r echo = T}
df.days <- data.frame(days_since_prior_order = c(rep(1,101),rep(15,101),rep(30,101)), frac = 0.01 * 0:100)
##
## Add a new column using the model to predict the response
##
df.days$response <- predict(dayfracfit, newdata = df.days, type = "response")
##
##
df.days$days_since_prior_order <- as.factor(df.days$days_since_prior_order) 
##
##
##
ggplot(df.days, aes(x = frac, y = response, colour = days_since_prior_order)) + geom_line(lwd = 2, alpha = 0.8)
```

As we saw in the case of using just `frac`, it isn't easy to predict where we should set the cutoff. But we know it should be for the value of frac equal to about 0.26; this corresponds to a value of the response variable around 0.126, depending on the length of time:
```{r echo = T}
predict(dayfracfit, newdata = data.frame(days_since_prior_order = c(1,15,30), frac = 0.26), type = "response")
```
So let's check some values in the region of 0.1 to 0.15. We'll use the training dataset again. We need to get a data frame with the order number, days since prior order, and `frac` variable.

```{r echo = T}
odpf <- orders %>% filter(eval_set == "train") %>% select(order_id, user_id, days_since_prior_order) %>% inner_join(orderfracs)

odpf$response <- predict(dayfracfit, newdata = odpf, type = "response")
```

```{r echo = T}
if(!file.exists("dayscores.rds")){
  day.scores <- NULL
  for(i in 0:20){
    p <- 0.1 + 0.0025 * i
    print(i)
    prod.pred <- odpf %>% filter(response >= p) %>% group_by(order_id) %>% mutate(products = paste0(product_id, collapse = " ")) %>% select(order_id, products) %>% unique()
    ##
    ##
    ##
    f1.scores <- train.to.f1(prod.pred)
    day.scores <- c(day.scores, mean(f1.scores$f1))
  }
  saveRDS(day.scores,"dayscores.RDS")
} else {
  day.scores <- readRDS("dayscores.rds")
}

if(!file.exists("dayscoresfine.rds")){
  day.scores.fine <- NULL
  for(i in 0:19){
    p <- 0.125 + 0.00025 * i
    print(i)
    prod.pred <- odpf %>% filter(response >= p) %>% group_by(order_id) %>% mutate(products = paste0(product_id, collapse = " ")) %>% select(order_id, products) %>% unique()
    ##
    ##
    ##
    f1.scores <- train.to.f1(prod.pred)
    day.scores.fine <- c(day.scores.fine, mean(f1.scores$f1))
  }
  saveRDS(day.scores.fine,"dayscoresfine.rds")
} else {
  day.scores.fine <- readRDS("dayscoresfine.rds")
}
```


```{r echo = T}
day.scores.df <- data.frame(cutoff = c(0.1 + 0.0025 * (0:20), 0.125 + 0.00025 * (0:19)), F1 = c(day.scores, day.scores.fine))

best.cutoff = 0.128125

ggplot(day.scores.df, aes(x = cutoff, y = F1)) + geom_line(lwd = 1) + geom_vline(xintercept = best.cutoff)
```

Using this model and this cutoff, let's predict the test dataset scores. First we need a data frame with the order numbers, fraction of prior purchases and the days since the previous purchase:
```{r echo = T}
test.odpf <- orders %>% filter(eval_set == "test") %>% select(order_id, user_id, days_since_prior_order) %>% inner_join(orderfracs)

test.odpf$response <- predict(dayfracfit, newdata = test.odpf, type = "response")

frac.day.pred <- test.odpf %>% filter(response >= best.cutoff) %>% group_by(order_id) %>% mutate(products = paste0(product_id, collapse = " ")) %>% select(order_id, products) %>% unique()

frac.day.pred.all <- filter(orders, eval_set == "test") %>% left_join(frac.day.pred) %>% select(order_id, products) %>% mutate(products = ifelse(is.na(products),"None",products))

write.csv(frac.day.pred.all, file = "fracdaypred.csv", quote = F, row.names = F)
```

This gives a score of 0.3321 --- slightly worse than the submission which *didn't* account for the number of days since the purchase occurred!

Let's have a look at how the responses are spread out. There are too many so we'll pick 1/10000 of the data randomly:
```{r echo = T}
inplot <- as.logical(
    rbinom(
        n = nrow(prodsinorderdays), 
        size = 1, 
        prob = 0.0001
    )
)
piodsmall <- prodsinorderdays %>% filter(inplot)
plot(piodsmall$frac, 1* piodsmall$inorder)
```

